{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U0EkDIvBXrO"
      },
      "source": [
        "## Table of contents:\n",
        "* Initial Setup\n",
        "* Data Loading and Preprocessing\n",
        "    * Data Variables\n",
        "* Model Instantiation\n",
        "* Optimizer and Scheduler\n",
        "* Train and Evaluation Loop\n",
        "    * Save the model and plot the losses (**1 Point**)\n",
        "* Test Loop  \n",
        "* Human Pose Visualization (**2 Points**)\n",
        "* Report and Parameter Fine-Tuning Analysis  (**4 Points**)\n",
        "* Calculating MPJPE for a Specific Frame  (**2 Points**)\n",
        "* Iterative Mechanism (**3 Points**)\n",
        "* YOUR custom model (**3 Points**)\n",
        "    * Performance BONUS (**Up to 2 Points**)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s2XUo8DBXrR"
      },
      "source": [
        "## Initial Setup\n",
        "Run the following two cellls to sync with Google Drive only if you run from Google Colab.\n",
        "\n",
        "*Note: we recommend using Google Colab for this specific homework, since the training phase will require a GPU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c-ZWnMV4BXrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a5e0ac-3636-4aa9-cc5d-83100c809f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqjWk6s-BXrS",
        "outputId": "8679bbd5-2da6-486c-e1bd-4413fbcb678e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AML/Practice\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AML/Practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIPz4YWBwbKq",
        "outputId": "deb7876f-5ee4-4386-9e60-a56a1d0cc55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: wandb: command not found\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfZFycIrBXrT"
      },
      "source": [
        "Welcome to this guide on training, testing, and fine-tuning a deep learning model. Deep learning is at the forefront of artificial intelligence, with applications spanning image recognition, natural language processing, and more.\n",
        "\n",
        "Throughout this assignment, you'll:\n",
        "\n",
        "1. **Prepare Data:** Preprocess and load the data.\n",
        "\n",
        "2. **Use Neural Networks:** Instantiate a neural network architecture.\n",
        "\n",
        "3. **Train Models:** Utilize optimization, loss functions, and backpropagation.\n",
        "\n",
        "4. **Evaluate Performance:** Assess model performance, prevent overfitting, and underfitting.\n",
        "\n",
        "5. **Fine-Tune Models:** Explore hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "7air6QP1tXsa"
      },
      "outputs": [],
      "source": [
        "from utils import h36motion3d as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch\n",
        "import numpy as np\n",
        "from utils.loss_funcs import *\n",
        "from utils.data_utils import define_actions\n",
        "from utils.h36_3d_viz import visualize\n",
        "import time\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5-P9Yj-tfBC",
        "outputId": "bbf14969-9cee-4430-a205-767416d8e614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda - Type: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Use GPU if available, otherwise stick with cpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device,  '- Type:', torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsK9hMdiBXrU"
      },
      "source": [
        "## Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-EC3XAqBXrV"
      },
      "source": [
        "For this homework, you will use [Human3.6M](https://vision.imar.ro/human3.6m/pami-h36m.pdf), which is a large-scale dataset of 3.6 million accurate 3D human poses acquired by recording the performance of five female and six male subjects under four different viewpoints. The dataset includes:\n",
        "- Synchronized image.\n",
        "- Human motion capture.\n",
        "- Time of flight (depth) data.\n",
        "- Accurate 3D body scans of all the subject actors involved.\n",
        "\n",
        "The dataset aims to provide diverse motions and poses encountered in typical human activities, with additional data to train realistic human sensing systems.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1nyD1_F3r1ctexKFGDmhy2Q9SX_2Z_bpS)\n",
        "\n",
        "For this assignment, we will leverage the rich **motion data** (See in the figure above) provided by H3.6M to perform a task known as *motion prediction*. Motion prediction involves using historical motion data to forecast future movements. This task is fundamental in human-robot interaction, animation, and sports analytics applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDVBcpLABXrV"
      },
      "source": [
        "### Data Variables\n",
        "\n",
        "Each created sequence has the shape (35, 17, 3), where:\n",
        "- Number of observed sequences and number of sequences to predict: $N_{obs}+N_{pred} = 10 + 25 = 35$;\n",
        "- Number of body joints to consider: $J=22$;\n",
        "- Spatial coordinates: $(x,y,z) = 3$.\n",
        "\n",
        "\n",
        "The original data provides high-resolution progressive scan videos at 50 Hz. However, the dataset has been downsampled to 25 Hz for research purposes. This means that 25 frames of motion data are provided per second.\n",
        "\n",
        "*Note: the figure above shows 18 joints, however the dataset contains 32. For this specific case we will consider 22 joints, ignoring some of the finer ones (e.g. foot tip, hand tip, etc)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "ZgNCWoUEBXrV"
      },
      "outputs": [],
      "source": [
        "# # Arguments to setup the datasets\n",
        "datas = 'h36m' # dataset name\n",
        "path = './data/h3.6m/h3.6m/dataset'\n",
        "input_n=10 # number of frames to train on (default=10)\n",
        "output_n=25 # number of frames to predict on\n",
        "input_dim=3 # dimensions of the input coordinates(default=3)\n",
        "skip_rate=1 # # skip rate of frames\n",
        "joints_to_consider=22\n",
        "\n",
        "\n",
        "#FLAGS FOR THE TRAINING\n",
        "mode='train' #choose either train or test mode\n",
        "\n",
        "batch_size_test=8\n",
        "model_path= './checkpoints/' # path to the model checkpoint file\n",
        "\n",
        "actions_to_consider_test='all' # actions to test on.\n",
        "model_name = datas+'_3d_'+str(output_n)+'frames_ckpt' #the model name to save/load\n",
        "\n",
        "#FLAGS FOR THE VISUALIZATION\n",
        "actions_to_consider_viz='all' # actions to visualize\n",
        "visualize_from='test'\n",
        "n_viz=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHrODi8VBXrW"
      },
      "source": [
        "Load Dataset\n",
        "\n",
        "*Note: It will take you ~ 5 minutes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "0GTflRxwBXrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2877c0-9c7a-409b-8fc0-ab9efe3b2e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Train Dataset...\n",
            "Loading Validation Dataset...\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "print('Loading Train Dataset...')\n",
        "dataset = datasets.Datasets(path,input_n,output_n,skip_rate, split=0)\n",
        "print('Loading Validation Dataset...')\n",
        "vald_dataset = datasets.Datasets(path,input_n,output_n,skip_rate, split=1)\n",
        "\n",
        "#! Note: Ignore warning:  \"VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBDfLkXfBXrW"
      },
      "source": [
        "Following we create a torch dataloader that create the batches for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "5RWNrUxIBXrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7993de60-ca32-410b-a18f-45238bce22c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Training dataset length: 180077\n",
            ">>> Validation dataset length: 28110\n"
          ]
        }
      ],
      "source": [
        "batch_size=256\n",
        "\n",
        "print('>>> Training dataset length: {:d}'.format(dataset.__len__()))\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)#\n",
        "\n",
        "print('>>> Validation dataset length: {:d}'.format(vald_dataset.__len__()))\n",
        "vald_loader = DataLoader(vald_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdFwJ4QuBXrX"
      },
      "source": [
        "## Model instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv7XT2pDBXrX"
      },
      "source": [
        "\n",
        "Each sequence comprises an **observed** part to train the Encoder and a part that attempts to predict the **future** sequence, the Decoder.\n",
        "\n",
        "Generally, the standard setup plans to use the first 10 sequences of poses ($N_{obs}=10$) for the observation and the following 25 ($N_{pred} = 25$) for the prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW7_ED1vBXrY"
      },
      "source": [
        "We create an instance of a custom Spatio-Temporal transformer with the chosen configuration.\n",
        "\n",
        "(*Note: explore the model in ./models/sttr/sttformer.py*)\n",
        "\n",
        "Then we allocate it to the GPU for forward and backward accelerated computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "9bDpLWl6BXrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b1cac8-e320-4aaf-fa65-f8f0931457ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "total number of parameters of the network is: 26859\n"
          ]
        }
      ],
      "source": [
        "from models.sttr.sttformer import Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n",
        "\n",
        "n_heads = 1\n",
        "\n",
        "model = Model(num_joints=joints_to_consider,\n",
        "                 num_frames=input_n, num_frames_out=output_n, num_heads=n_heads,\n",
        "                 num_channels=3, kernel_size=[3,3], use_pes=True).to(device)\n",
        "\n",
        "print('total number of parameters of the network is: '+str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBtix_WjBXrY"
      },
      "source": [
        "## Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XtIPG_IBXrY"
      },
      "source": [
        "As we embark on training deep learning models for motion prediction using the H3.6M dataset, it's essential to recognize several key parameters and components that significantly impact the training phase:\n",
        "\n",
        "- **Learning Rate:** This parameter determines the convergence speed during optimization.\n",
        "\n",
        "- **Batch Size:** It influences model generalization and training efficiency.\n",
        "\n",
        "- **Number of Epochs:** The number of training iterations affects model learning.\n",
        "\n",
        "- **Loss Function:** The choice of loss function directly affects learning and final performance.\n",
        "\n",
        "- **Optimizer:** The optimization algorithm used (e.g., Adam, SGD) impacts gradient descent during training.\n",
        "\n",
        "- **Milestones and Gamma:** These parameters control learning rate schedules, allowing for adaptive adjustments during training.\n",
        "\n",
        "- **Weight Decay:** It regulates the impact of model parameters during optimization.\n",
        "\n",
        "- **Scheduler:** Scheduler strategies (e.g., StepLR, ReduceLROnPlateau) manage learning rate adaptation during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "ILUrD5v4BXrZ"
      },
      "outputs": [],
      "source": [
        "# Arguments to setup the optimizer\n",
        "lr=1e-01 # learning rate\n",
        "use_scheduler=True # use MultiStepLR scheduler\n",
        "milestones=[10,30]   # the epochs after which the learning rate is adjusted by gamma\n",
        "gamma=0.1 #gamma correction to the learning rate, after reaching the milestone epochs\n",
        "weight_decay=1e-05 # weight decay (L2 penalty)\n",
        "optimizer=optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "if use_scheduler:\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "9lfkuKP1BXra"
      },
      "outputs": [],
      "source": [
        "clip_grad=None # select max norm to clip gradients\n",
        "# Argument for training\n",
        "n_epochs=41\n",
        "log_step = 700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "C8zw7pxyxaO-"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "lim_n_batches_percent = 0.05\n",
        "step_size = 30\n",
        "\n",
        "train_id = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "ckpt_dir = f\"{model_path}{train_id}\"\n",
        "os.makedirs(ckpt_dir) if not os.path.exists(ckpt_dir) else None\n",
        "\n",
        "\n",
        "train_config = {\n",
        "  \"batch_size\": batch_size,\n",
        "  \"lim_n_batches_percent\": lim_n_batches_percent,\n",
        "  \"n_heads\": n_heads,\n",
        "  \"model\": model,\n",
        "  \"num_trainable_parameters\": str(sum(p.numel() for p in model.parameters() if p.requires_grad)),\n",
        "  \"lr\": lr,\n",
        "  \"use_scheduler\": use_scheduler,\n",
        "  \"milestones\": milestones,\n",
        "  \"gamma\": gamma,\n",
        "  \"step_size\": step_size,\n",
        "  \"weight_decay\": weight_decay,\n",
        "  \"optimizer\": optimizer,\n",
        "  \"scheduler\": scheduler if use_scheduler else None,\n",
        "  \"clip_grad\": clip_grad,\n",
        "  \"n_epochs\": n_epochs,\n",
        "  \"train_id\": train_id\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTbGwJFtBXra"
      },
      "source": [
        "## Train and Evaluation Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBT0Z7FLBXrb"
      },
      "source": [
        "The **loss** and **metric** used during training and evaluation respectively, compare the predicted joint positions to ground truth joint positions for all frames, which is typically referred to as the **Average Mean Per\n",
        "Joint Position Error (A-MPJPE)** can be seen as an $L_2$. This loss quantifies the dissimilarity between the predicted and ground truth joint positions by measuring the squared Euclidean distance between corresponding joint positions.\n",
        "\n",
        "\\begin{align*}\n",
        "A-MPJPE &= \\frac{1}{N_{pred}} \\sum_{i=1}^{N_{pred}} \\left(\\frac{1}{J} \\sum_{j=1}^{J} \\left\\| P_{\\text{predicted}_{t,j}} - P_{\\text{gt}_{t,j}} \\right\\|^2\\right)\n",
        "\\end{align*}\n",
        "\n",
        "$$where:$$\n",
        "\n",
        "\\begin{align*}\n",
        "P_{\\text{predicted}} &: \\text{Set of predicted joint positions estimated by the model.} \\\\\n",
        "P_{\\text{gt}} &: \\text{Corresponding set of ground truth joint positions.} \\\\\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lriDKsUoBXrb"
      },
      "source": [
        "*Note: If you restart the training for any reason, remember to instantiate the model and the optimizer again. This will avoid continuing the training with the initialized weights of the previous one*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hiF0f6oBXrb"
      },
      "source": [
        "### Save the model and plot the losses (1 Point)\n",
        "\n",
        "**Objective:** In this exercise, you will practice implementing a code snippet to save your deep learning model's checkpoints and visualize the training and validation loss on the same plot every 5 epochs during model training.\n",
        "\n",
        "Your task is to implement the following:\n",
        "\n",
        "- Set up a mechanism to save the model's checkpoints (weights and architecture) during training. These checkpoints should be saved periodically, say, **every 5 epochs**.\n",
        "\n",
        "- Create a plot displaying the training and validation losses on the same graph. The x-axis should represent the number of epochs, and the y-axis should represent the loss values. The training and validation losses should be plotted as separate lines on the same graph.\n",
        "\n",
        "- Ensure that the code saves the model's checkpoints in a specified directory, including the model's architecture and weights, and that the loss plot is displayed.\n",
        "\n",
        "Analyze the loss plot to gain insights into how your model is learning over time and whether there are any signs of overfitting or underfitting.\n",
        "\n",
        "*Note: see the Pytorch Documentation on how to save your model's checkpoints.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQUGhkJPuoF8"
      },
      "outputs": [],
      "source": [
        "def train(data_loader,vald_loader, path_to_save_model=None):\n",
        "\n",
        "  n_train_batches = int(len(data_loader) * lim_n_batches_percent) + 1\n",
        "  n_val_batches = int(len(vald_loader) * lim_n_batches_percent) + 1\n",
        "\n",
        "  #TODO controlla errore: metodo non esisteva\n",
        "  wandb.init(project=\"Spatio-Temporal Transformer fine-tuning\", config=train_config)\n",
        "\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  val_loss_best = 1000\n",
        "\n",
        "  dim_used = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25,\n",
        "                    26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
        "                    46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68,\n",
        "                    75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92])\n",
        "\n",
        "  # Create a figure and axis for the plot\n",
        "  fig, ax = plt.subplots()\n",
        "  lines, = ax.plot([], [], 'b', label='Training Loss')\n",
        "  lines2, = ax.plot([], [], 'r', label='Validation Loss')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.set_title('Training and Validation Loss')\n",
        "  ax.legend()\n",
        "\n",
        "  for epoch in range(n_epochs-1):\n",
        "      running_loss=0\n",
        "      n=0\n",
        "      model.train()\n",
        "      for cnt,batch in enumerate(data_loader):\n",
        "          batch=batch.float().to(device)\n",
        "          batch_dim=batch.shape[0]\n",
        "          n+=batch_dim\n",
        "\n",
        "          sequences_train=batch[:, 0:input_n, dim_used].view(-1,input_n,len(dim_used)//3,3).permute(0,3,1,2)\n",
        "          sequences_gt=batch[:, input_n:input_n+output_n, dim_used].view(-1,output_n,len(dim_used)//3,3)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          sequences_predict=model(sequences_train).view(-1, output_n, joints_to_consider, 3)\n",
        "\n",
        "\n",
        "          loss=mpjpe_error(sequences_predict,sequences_gt)\n",
        "\n",
        "\n",
        "          if cnt % log_step == 0:\n",
        "            print('[Epoch: %d, Iteration: %5d]  training loss: %.3f' %(epoch + 1, cnt + 1, loss.item()))\n",
        "\n",
        "          loss.backward()\n",
        "          if clip_grad is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),clip_grad)\n",
        "\n",
        "          optimizer.step()\n",
        "          running_loss += loss*batch_dim\n",
        "\n",
        "      train_loss.append(running_loss.detach().cpu()/n)\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          running_loss=0\n",
        "          n=0\n",
        "          for cnt,batch in enumerate(vald_loader):\n",
        "              batch=batch.float().to(device)\n",
        "              batch_dim=batch.shape[0]\n",
        "              n+=batch_dim\n",
        "\n",
        "\n",
        "              sequences_train=batch[:, 0:input_n, dim_used].view(-1,input_n,len(dim_used)//3,3).permute(0,3,1,2)\n",
        "              sequences_gt=batch[:, input_n:input_n+output_n, dim_used].view(-1,output_n,len(dim_used)//3,3)\n",
        "\n",
        "              sequences_predict=model(sequences_train).view(-1, output_n, joints_to_consider, 3)\n",
        "              loss=mpjpe_error(sequences_predict,sequences_gt)\n",
        "\n",
        "              if cnt % log_step == 0:\n",
        "                        print('[Epoch: %d, Iteration: %5d]  validation loss: %.3f' %(epoch + 1, cnt + 1, loss.item()))\n",
        "              running_loss+=loss*batch_dim\n",
        "          val_loss.append(running_loss.detach().cpu()/n)\n",
        "          if running_loss/n < val_loss_best:\n",
        "            val_loss_best = running_loss/n\n",
        "\n",
        "      if use_scheduler:\n",
        "        scheduler.step()\n",
        "\n",
        "      # save and plot model every 5 epochs\n",
        "      '''\n",
        "      Insert your code below. Use the argument path_to_save_model to save the model to the path specified.\n",
        "      '''\n",
        "\n",
        "      if save_and_plot:\n",
        "        torch.save(model.state_dict(), path_to_save_model + model_name + \"_epoch_\" + str(epoch+1) + \".pt\")\n",
        "\n",
        "        lines.set_data(range(1, epoch+2), train_loss)\n",
        "        lines2.set_data(range(1, epoch+2), val_loss)\n",
        "        ax.relim()\n",
        "        ax.autoscale_view()\n",
        "\n",
        "        # Redraw the figure\n",
        "        fig.canvas.draw()\n",
        "\n",
        "        #wandb.log({\n",
        "        #  \"epoch\": epoch,\n",
        "        #  \"loss/train\": train_loss[-1],\n",
        "        #  \"loss/val\": val_loss[-1]\n",
        "        #})\n",
        "\n",
        "  # Display the plot when done\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad1335a70ab64f1e82759084cf3521bd",
            "26dd3a1731e64a9b819005d7cd8e7996",
            "3e865a34ac0842fa8d2bb5b311ae5511",
            "e6bff14e4b7244a09655883fb34c1703",
            "1ccdd086b475483295de6391f9f469dc",
            "882027c62aee457884ca9ae347777451",
            "48d6bca113864643ad01f43633f10d9c",
            "7286a39848c548d48d6a94d9b87adf6e"
          ]
        },
        "id": "uPWGWLHTBXrd",
        "outputId": "21f95d24-82e2-4e75-de9c-184d88b33442"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:35bt5m3q) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad1335a70ab64f1e82759084cf3521bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>loss/train</td><td>█▁</td></tr><tr><td>loss/val</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>loss/train</td><td>87.43213</td></tr><tr><td>loss/val</td><td>83.90468</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">zesty-music-1</strong> at: <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/35bt5m3q' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/35bt5m3q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231022_142723-35bt5m3q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:35bt5m3q). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/AML/Practice/wandb/run-20231022_144618-kuzjza0l</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/kuzjza0l' target=\"_blank\">hopeful-darkness-2</a></strong> to <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/kuzjza0l' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/kuzjza0l</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, Iteration:     1]  training loss: 555.293\n",
            "[Epoch: 1, Iteration:   701]  training loss: 107.734\n",
            "[Epoch: 1, Iteration:     1]  validation loss: 103.025\n",
            "[Epoch: 2, Iteration:     1]  training loss: 102.781\n",
            "[Epoch: 2, Iteration:   701]  training loss: 93.623\n",
            "[Epoch: 2, Iteration:     1]  validation loss: 90.255\n",
            "[Epoch: 3, Iteration:     1]  training loss: 94.176\n",
            "[Epoch: 3, Iteration:   701]  training loss: 96.855\n",
            "[Epoch: 3, Iteration:     1]  validation loss: 95.450\n",
            "[Epoch: 4, Iteration:     1]  training loss: 96.870\n",
            "[Epoch: 4, Iteration:   701]  training loss: 95.509\n",
            "[Epoch: 4, Iteration:     1]  validation loss: 89.209\n",
            "[Epoch: 5, Iteration:     1]  training loss: 88.158\n",
            "[Epoch: 5, Iteration:   701]  training loss: 93.298\n",
            "[Epoch: 5, Iteration:     1]  validation loss: 83.830\n",
            "[Epoch: 6, Iteration:     1]  training loss: 90.532\n",
            "[Epoch: 6, Iteration:   701]  training loss: 92.783\n",
            "[Epoch: 6, Iteration:     1]  validation loss: 83.225\n",
            "[Epoch: 7, Iteration:     1]  training loss: 88.432\n",
            "[Epoch: 7, Iteration:   701]  training loss: 89.495\n",
            "[Epoch: 7, Iteration:     1]  validation loss: 84.257\n",
            "[Epoch: 8, Iteration:     1]  training loss: 86.484\n",
            "[Epoch: 8, Iteration:   701]  training loss: 85.207\n",
            "[Epoch: 8, Iteration:     1]  validation loss: 84.154\n",
            "[Epoch: 9, Iteration:     1]  training loss: 88.307\n",
            "[Epoch: 9, Iteration:   701]  training loss: 90.952\n",
            "[Epoch: 9, Iteration:     1]  validation loss: 89.778\n",
            "[Epoch: 10, Iteration:     1]  training loss: 87.870\n",
            "[Epoch: 10, Iteration:   701]  training loss: 82.412\n",
            "[Epoch: 10, Iteration:     1]  validation loss: 80.084\n",
            "[Epoch: 11, Iteration:     1]  training loss: 90.713\n",
            "[Epoch: 11, Iteration:   701]  training loss: 83.130\n",
            "[Epoch: 11, Iteration:     1]  validation loss: 82.505\n",
            "[Epoch: 12, Iteration:     1]  training loss: 82.875\n",
            "[Epoch: 12, Iteration:   701]  training loss: 87.016\n",
            "[Epoch: 12, Iteration:     1]  validation loss: 79.835\n",
            "[Epoch: 13, Iteration:     1]  training loss: 82.109\n",
            "[Epoch: 13, Iteration:   701]  training loss: 83.385\n",
            "[Epoch: 13, Iteration:     1]  validation loss: 79.587\n",
            "[Epoch: 14, Iteration:     1]  training loss: 84.035\n",
            "[Epoch: 14, Iteration:   701]  training loss: 83.259\n",
            "[Epoch: 14, Iteration:     1]  validation loss: 79.025\n",
            "[Epoch: 15, Iteration:     1]  training loss: 83.026\n",
            "[Epoch: 15, Iteration:   701]  training loss: 81.637\n",
            "[Epoch: 15, Iteration:     1]  validation loss: 77.823\n",
            "[Epoch: 16, Iteration:     1]  training loss: 84.294\n",
            "[Epoch: 16, Iteration:   701]  training loss: 85.780\n",
            "[Epoch: 16, Iteration:     1]  validation loss: 76.916\n",
            "[Epoch: 17, Iteration:     1]  training loss: 78.893\n",
            "[Epoch: 17, Iteration:   701]  training loss: 82.181\n",
            "[Epoch: 17, Iteration:     1]  validation loss: 77.654\n",
            "[Epoch: 18, Iteration:     1]  training loss: 87.450\n",
            "[Epoch: 18, Iteration:   701]  training loss: 80.979\n",
            "[Epoch: 18, Iteration:     1]  validation loss: 78.567\n",
            "[Epoch: 19, Iteration:     1]  training loss: 82.860\n",
            "[Epoch: 19, Iteration:   701]  training loss: 86.085\n",
            "[Epoch: 19, Iteration:     1]  validation loss: 76.983\n",
            "[Epoch: 20, Iteration:     1]  training loss: 86.957\n",
            "[Epoch: 20, Iteration:   701]  training loss: 84.038\n",
            "[Epoch: 20, Iteration:     1]  validation loss: 79.910\n",
            "[Epoch: 21, Iteration:     1]  training loss: 85.576\n",
            "[Epoch: 21, Iteration:   701]  training loss: 81.887\n",
            "[Epoch: 21, Iteration:     1]  validation loss: 81.634\n",
            "[Epoch: 22, Iteration:     1]  training loss: 85.152\n",
            "[Epoch: 22, Iteration:   701]  training loss: 79.896\n",
            "[Epoch: 22, Iteration:     1]  validation loss: 76.878\n",
            "[Epoch: 23, Iteration:     1]  training loss: 82.823\n",
            "[Epoch: 23, Iteration:   701]  training loss: 85.373\n",
            "[Epoch: 23, Iteration:     1]  validation loss: 73.133\n",
            "[Epoch: 24, Iteration:     1]  training loss: 78.765\n",
            "[Epoch: 24, Iteration:   701]  training loss: 82.106\n",
            "[Epoch: 24, Iteration:     1]  validation loss: 77.454\n",
            "[Epoch: 25, Iteration:     1]  training loss: 83.432\n",
            "[Epoch: 25, Iteration:   701]  training loss: 89.350\n",
            "[Epoch: 25, Iteration:     1]  validation loss: 75.251\n",
            "[Epoch: 26, Iteration:     1]  training loss: 80.008\n",
            "[Epoch: 26, Iteration:   701]  training loss: 79.592\n",
            "[Epoch: 26, Iteration:     1]  validation loss: 83.274\n",
            "[Epoch: 27, Iteration:     1]  training loss: 83.000\n",
            "[Epoch: 27, Iteration:   701]  training loss: 82.201\n",
            "[Epoch: 27, Iteration:     1]  validation loss: 77.812\n",
            "[Epoch: 28, Iteration:     1]  training loss: 85.501\n",
            "[Epoch: 28, Iteration:   701]  training loss: 84.105\n",
            "[Epoch: 28, Iteration:     1]  validation loss: 82.975\n",
            "[Epoch: 29, Iteration:     1]  training loss: 78.959\n",
            "[Epoch: 29, Iteration:   701]  training loss: 83.746\n",
            "[Epoch: 29, Iteration:     1]  validation loss: 78.518\n",
            "[Epoch: 30, Iteration:     1]  training loss: 79.997\n",
            "[Epoch: 30, Iteration:   701]  training loss: 82.376\n",
            "[Epoch: 30, Iteration:     1]  validation loss: 78.479\n",
            "[Epoch: 31, Iteration:     1]  training loss: 87.481\n",
            "[Epoch: 31, Iteration:   701]  training loss: 76.929\n",
            "[Epoch: 31, Iteration:     1]  validation loss: 79.741\n",
            "[Epoch: 32, Iteration:     1]  training loss: 81.849\n",
            "[Epoch: 32, Iteration:   701]  training loss: 78.750\n",
            "[Epoch: 32, Iteration:     1]  validation loss: 77.071\n",
            "[Epoch: 33, Iteration:     1]  training loss: 82.498\n",
            "[Epoch: 33, Iteration:   701]  training loss: 83.792\n",
            "[Epoch: 33, Iteration:     1]  validation loss: 76.381\n",
            "[Epoch: 34, Iteration:     1]  training loss: 78.901\n",
            "[Epoch: 34, Iteration:   701]  training loss: 84.935\n",
            "[Epoch: 34, Iteration:     1]  validation loss: 79.907\n",
            "[Epoch: 35, Iteration:     1]  training loss: 81.653\n",
            "[Epoch: 35, Iteration:   701]  training loss: 85.575\n",
            "[Epoch: 35, Iteration:     1]  validation loss: 75.705\n",
            "[Epoch: 36, Iteration:     1]  training loss: 83.156\n",
            "[Epoch: 36, Iteration:   701]  training loss: 78.056\n",
            "[Epoch: 36, Iteration:     1]  validation loss: 77.722\n",
            "[Epoch: 37, Iteration:     1]  training loss: 82.120\n",
            "[Epoch: 37, Iteration:   701]  training loss: 80.232\n",
            "[Epoch: 37, Iteration:     1]  validation loss: 76.154\n",
            "[Epoch: 38, Iteration:     1]  training loss: 84.555\n",
            "[Epoch: 38, Iteration:   701]  training loss: 77.632\n",
            "[Epoch: 38, Iteration:     1]  validation loss: 79.602\n",
            "[Epoch: 39, Iteration:     1]  training loss: 79.575\n",
            "[Epoch: 39, Iteration:   701]  training loss: 73.917\n",
            "[Epoch: 39, Iteration:     1]  validation loss: 76.124\n",
            "[Epoch: 40, Iteration:     1]  training loss: 79.319\n",
            "[Epoch: 40, Iteration:   701]  training loss: 79.663\n",
            "[Epoch: 40, Iteration:     1]  validation loss: 78.279\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "save_and_plot = True # save the model and plot the loss. Change to True if you want to save the model and plot the loss\n",
        "\n",
        "# launch training\n",
        "train(data_loader,vald_loader, path_to_save_model=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVcwUPM6BXrd"
      },
      "source": [
        "## Test Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrR1AEWoBXre"
      },
      "source": [
        "After training and validation, the test loop is the final phase that evaluates the model's performance on an entirely independent dataset known as the test dataset. This dataset is distinct from the training and validation data, ensuring unbiased assessment. The test loop provides a reliable estimate of how well the model will perform in real-world scenarios, confirming that any improvements observed during training and validation are not due to overfitting or chance. It's a crucial step before deploying the model in practical applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "AjwwPPMNxjJ2"
      },
      "outputs": [],
      "source": [
        "def test(ckpt_path=None):\n",
        "\n",
        "\n",
        "    action_loss_dict = {}\n",
        "    n_test_batches = int(len(data_loader) * lim_n_batches_percent) + 1\n",
        "\n",
        "    model.load_state_dict(torch.load(ckpt_path))\n",
        "    print('model loaded')\n",
        "    model.eval()\n",
        "    accum_loss=0\n",
        "    n_batches=0 # number of batches for all the sequences\n",
        "    actions=define_actions(actions_to_consider_test)\n",
        "    dim_used = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25,\n",
        "                      26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
        "                      46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68,\n",
        "                      75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92])\n",
        "    # joints at same loc\n",
        "    joint_to_ignore = np.array([16, 20, 23, 24, 28, 31])\n",
        "    index_to_ignore = np.concatenate((joint_to_ignore * 3, joint_to_ignore * 3 + 1, joint_to_ignore * 3 + 2))\n",
        "    joint_equal = np.array([13, 19, 22, 13, 27, 30])\n",
        "    index_to_equal = np.concatenate((joint_equal * 3, joint_equal * 3 + 1, joint_equal * 3 + 2))\n",
        "    totalll=0\n",
        "    counter=0\n",
        "    for action in actions:\n",
        "      running_loss=0\n",
        "      n=0\n",
        "      dataset_test = datasets.Datasets(path,input_n,output_n,skip_rate, split=2,actions=[action])\n",
        "      #print('>>> test action for sequences: {:d}'.format(dataset_test.__len__()))\n",
        "\n",
        "      test_loader = DataLoader(dataset_test, batch_size=batch_size_test, shuffle=False, num_workers=0, pin_memory=True)\n",
        "      for cnt,batch in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "\n",
        "          batch=batch.to(device)\n",
        "          batch_dim=batch.shape[0]\n",
        "          n+=batch_dim\n",
        "\n",
        "\n",
        "          all_joints_seq=batch.clone()[:, input_n:input_n+output_n,:]\n",
        "\n",
        "          sequences_train=batch[:, 0:input_n, dim_used].view(-1,input_n,len(dim_used)//3,3).permute(0,3,1,2)\n",
        "          sequences_gt=batch[:, input_n:input_n+output_n, :]\n",
        "\n",
        "\n",
        "          running_time = time.time()\n",
        "          sequences_predict=model(sequences_train).view(-1, output_n, joints_to_consider, 3)\n",
        "          #sequences_predict = model(sequences_train)\n",
        "          totalll += time.time()-running_time\n",
        "          counter += 1\n",
        "          sequences_predict=sequences_predict.contiguous().view(-1,output_n,len(dim_used))\n",
        "\n",
        "          all_joints_seq[:,:,dim_used] = sequences_predict\n",
        "\n",
        "\n",
        "          all_joints_seq[:,:,index_to_ignore] = all_joints_seq[:,:,index_to_equal]\n",
        "\n",
        "          loss=mpjpe_error(all_joints_seq.view(-1,output_n,32,3),sequences_gt.view(-1,output_n,32,3))\n",
        "          running_loss+=loss*batch_dim\n",
        "          accum_loss+=loss*batch_dim\n",
        "\n",
        "      #print('loss at test subject for action : '+str(action)+ ' is: '+ str(running_loss/n))\n",
        "      print(str(action),': ', str(np.round((running_loss/n).item(),1)))\n",
        "\n",
        "      action_loss_dict[f\"loss/test/{action}\"] = np.round((running_loss/n).item(),1)\n",
        "\n",
        "      n_batches+=n\n",
        "\n",
        "    action_loss_dict[\"loss/test\"] = np.round((accum_loss/n_batches).item(),1)\n",
        "    #wandb.log(action_loss_dict)\n",
        "\n",
        "    print('Average: '+str(np.round((accum_loss/n_batches).item(),1)))\n",
        "    print('Prediction time: ', totalll/counter)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2TrFIWDBXre"
      },
      "source": [
        "*Note: Your results should be better than 95 millimiters on average*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCt0vtOkvCxy",
        "outputId": "b5f97726-73f5-4447-aa54-0aae3e1c2ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded\n",
            "walking :  61.8\n",
            "eating :  58.8\n",
            "smoking :  59.0\n",
            "discussion :  86.9\n",
            "directions :  78.2\n",
            "greeting :  100.8\n",
            "phoning :  73.8\n",
            "posing :  116.7\n",
            "purchases :  99.7\n",
            "sitting :  86.6\n",
            "sittingdown :  109.1\n",
            "takingphoto :  86.6\n",
            "waiting :  80.9\n",
            "walkingdog :  111.5\n",
            "walkingtogether :  60.7\n",
            "Average: 84.7\n",
            "Prediction time:  0.008254618942737579\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = './checkpoints/h36m_3d_25frames_ckpt_epoch_40.pt' # Change the epoch according to the validation curve\n",
        "test(ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iELEXXORBXrf"
      },
      "source": [
        "## Human Pose Visualization  (**2 Points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dShZAp9BXrg"
      },
      "source": [
        "The qualitative results are as important as the quantitative ones. In this section, you will visualize and compare the predicted poses with the ground truth ones.\n",
        "For simplicity, you will visualize only the first predicted pose and the ground truth.\n",
        "\n",
        "Ideally, the same plot should show the predicted pose in red and the ground truth one in green.\n",
        "\n",
        "*Note: you will find which nodes are connected in the file ./models/skeleton_connection.py*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYxULFpgBXrg"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Insert your code below\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.animation as animation\n",
        "from utils import h36motion3d as datasets\n",
        "from utils.loss_funcs import mpjpe_error\n",
        "from utils.data_utils import define_actions\n",
        "\n",
        "# Define the function for creating the pose visualization\n",
        "def create_pose(ax, plots, vals, pred=True, update=False):\n",
        "    # Define connections between joints and their properties\n",
        "    connect = [(1, 2), (2, 3), (3, 4), (4, 5), (6, 7), (7, 8), (8, 9), (9, 10),\n",
        "               (0, 1), (0, 6), (6, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22),\n",
        "               (1, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (24, 25),\n",
        "               (24, 17), (24, 14), (14, 15)]\n",
        "\n",
        "    # Specify whether joints are on the left or right side\n",
        "    LR = [False, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True,\n",
        "          True, False, False, False, False, False, False, False, True, False, True, True, True, True, True, True]\n",
        "\n",
        "    # Start and endpoints of our representation\n",
        "    I = np.array([touple[0] for touple in connect])\n",
        "    J = np.array([touple[1] for touple in connect])\n",
        "\n",
        "    #green = prediction\n",
        "    if pred:\n",
        "        lcolor = \"green\"\n",
        "        rcolor = \"green\"\n",
        "\n",
        "    #red = gt\n",
        "    else:\n",
        "        lcolor = \"red\"\n",
        "        rcolor = \"red\"\n",
        "\n",
        "    for i in np.arange(len(I)):\n",
        "        x = np.array([vals[I[i], 0], vals[J[i], 0]])\n",
        "        z = np.array([vals[I[i], 1], vals[J[i], 1]])\n",
        "        y = np.array([vals[I[i], 2], vals[J[i], 2]])\n",
        "\n",
        "        if not update:\n",
        "            if i == 0:\n",
        "                plots.append(ax.plot(x, y, z, lw=2, linestyle='--', c=lcolor if LR[i] else rcolor, label=['Input Frames' if not pred else 'Predicted Frames']))\n",
        "            else:\n",
        "                plots.append(ax.plot(x, y, z, lw=2, linestyle='--', c=lcolor if LR[i] else rcolor))\n",
        "        elif update:\n",
        "            plots[i][0].set_xdata(x)\n",
        "            plots[i][0].set_ydata(y)\n",
        "            plots[i][0].set_3d_properties(z)\n",
        "            plots[i][0].set_color(lcolor if LR[i] else rcolor)\n",
        "\n",
        "    return plots\n",
        "\n",
        "# Define the update function for the animation\n",
        "def update(num, data_gt, data_pred, plots_gt, plots_pred, fig, ax):\n",
        "    gt_vals = data_gt[num]\n",
        "    pred_vals = data_pred[num]\n",
        "\n",
        "    #print(\"data_gt\")\n",
        "    #print(data_gt[0])\n",
        "\n",
        "    #print(\"data_pred\")\n",
        "    #print(data_pred[0])\n",
        "\n",
        "    #print(\"gt_vals\")\n",
        "    #print(gt_vals)\n",
        "    #print(\"pred vals\")\n",
        "    #print(pred_vals)\n",
        "    plots_gt = create_pose(ax, plots_gt, gt_vals, pred=False, update=True)\n",
        "    plots_pred = create_pose(ax, plots_pred, pred_vals, pred=True, update=True)\n",
        "\n",
        "    r = 0.75\n",
        "    xroot, zroot, yroot = pred_vals[0, 0], pred_vals[0, 1], pred_vals[0, 2]\n",
        "    ax.set_xlim3d([-r + xroot, r + xroot])\n",
        "    ax.set_ylim3d([-r + yroot, r + yroot])\n",
        "    ax.set_zlim3d([-r + zroot, r + zroot])\n",
        "\n",
        "    return plots_gt, plots_pred\n",
        "\n",
        "# Define the visualization function\n",
        "def visualize(input_n, output_n, visualize_from, path, modello, device, n_viz, skip_rate, actions):\n",
        "    actions = define_actions(actions)\n",
        "\n",
        "    modello.load_state_dict(torch.load(ckpt_path))\n",
        "\n",
        "    for action in actions:\n",
        "        if visualize_from == 'train':\n",
        "            loader = datasets.Datasets(path, input_n, output_n, skip_rate, split=0, actions=[action])\n",
        "        elif visualize_from == 'validation':\n",
        "            loader = datasets.Datasets(path, input_n, output_n, skip_rate, split=1, actions=[action])\n",
        "        elif visualize_from == 'test':\n",
        "            loader = datasets.Datasets(path, input_n, output_n, skip_rate, split=2, actions=[action])\n",
        "\n",
        "        dim_used = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92])\n",
        "        joint_to_ignore = np.array([16, 20, 23, 24, 28, 31])\n",
        "        index_to_ignore = np.concatenate((joint_to_ignore * 3, joint_to_ignore * 3 + 1, joint_to_ignore * 3 + 2))\n",
        "        joint_equal = np.array([13, 19, 22, 13, 27, 30])\n",
        "        index_to_equal = np.concatenate((joint_equal * 3, joint_equal * 3 + 1, joint_equal * 3 + 2))\n",
        "\n",
        "        loader = DataLoader(loader, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "        # predict poses\n",
        "        for cnt, batch in enumerate(loader):\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            all_joints_seq = batch.clone()[:, input_n:input_n + output_n, :]\n",
        "\n",
        "            sequences_train = batch[:, 0:input_n, dim_used].view(-1, input_n, len(dim_used)//3, 3).permute(0, 3, 1, 2)\n",
        "            sequences_gt = batch[:, input_n:input_n + output_n, :]\n",
        "\n",
        "            # shape is batch,n_frames,n_joints * 3(xyz)\n",
        "            sequences_predict = modello(sequences_train).contiguous().view(-1, output_n, len(dim_used))\n",
        "\n",
        "            all_joints_seq[:, :, dim_used] = sequences_predict\n",
        "\n",
        "            all_joints_seq[:, :, index_to_ignore] = all_joints_seq[:, :, index_to_equal]\n",
        "\n",
        "            all_joints_seq = all_joints_seq.view(-1, output_n, 32, 3)\n",
        "            sequences_gt = sequences_gt.view(-1, output_n, 32, 3)\n",
        "\n",
        "            loss = mpjpe_error(all_joints_seq, sequences_gt)\n",
        "\n",
        "            data_pred = torch.squeeze(all_joints_seq, 0).cpu().data.numpy() /1000  # in meters\n",
        "            data_gt = torch.squeeze(sequences_gt, 0).cpu().data.numpy() / 1000\n",
        "\n",
        "            fig = plt.figure()\n",
        "            # create the three axes\n",
        "            ax = fig.add_subplot(111, projection='3d')\n",
        "            # 32 is the number of joints, 3 is the directions\n",
        "            vals = np.zeros((32, 3))\n",
        "            gt_plots = []\n",
        "            pred_plots = []\n",
        "\n",
        "            gt_plots = create_pose(ax, gt_plots, vals, pred=False, update=False)\n",
        "            pred_plots = create_pose(ax, pred_plots, vals, pred=True, update=False)\n",
        "\n",
        "            ax.set_xlabel(\"x\")\n",
        "            ax.set_ylabel(\"y\")\n",
        "            ax.set_zlabel(\"z\")\n",
        "            ax.set_axis_off()\n",
        "            ax.legend(loc='lower left')\n",
        "\n",
        "            ax.set_xlim3d([-1, 1.5])\n",
        "            ax.set_xlabel('X')\n",
        "\n",
        "            ax.set_ylim3d([-1, 1.5])\n",
        "            ax.set_ylabel('Y')\n",
        "\n",
        "            ax.set_zlim3d([0.0, 1.5])\n",
        "            ax.set_zlabel('Z')\n",
        "\n",
        "            # create animation using update function (output_n specifies the number of frame to generate)\n",
        "            line_anim = animation.FuncAnimation(fig, update, output_n, fargs=(data_gt, data_pred, gt_plots, pred_plots, fig, ax), interval=70, blit=False)\n",
        "\n",
        "            line_anim.save('human_viz2.gif', writer='pillow')\n",
        "\n",
        "            if cnt == n_viz - 1:\n",
        "                break\n",
        "\n",
        "            #break\n",
        "\n",
        "        #break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTsNyarOAXuc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Insert your code below\n",
        "'''\n",
        "# instantiate the a new model as before\n",
        "model = Model(num_joints=joints_to_consider,\n",
        "                 num_frames=input_n, num_frames_out=output_n, num_heads=n_heads,\n",
        "                 num_channels=3, kernel_size=[3,3], use_pes=True).to(device)\n",
        "\n",
        "# n_viz = 1 only one gif\n",
        "visualize(input_n, output_n, visualize_from=visualize_from, path=path, modello=model, device=device,n_viz=n_viz, skip_rate=1, actions=actions_to_consider_viz)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfh69SDiBXrh"
      },
      "source": [
        "## Report and Parameter Fine-Tuning Analysis  (**4 Points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOcLSDxkBXrh"
      },
      "source": [
        "**Objective:** In this exercise, you will analyze the results obtained from a deep learning model you previously trained and perform parameter fine-tuning to optimize its performance. The key considerations are learning rate, milestones, and weight decay. **You will also use tables and plots to visualize and interpret the outcomes.**\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. **Analysis:** Analyze the generated report and answer the following questions:\n",
        "   - Is there evidence of overfitting or underfitting in the initial training results?\n",
        "   - Are there fluctuations in training and validation loss or accuracy? If so, what might be causing them?\n",
        "   - What can you infer from the initial learning rate, milestones, and weight decay settings?\n",
        "\n",
        "2. **Parameter Fine-Tuning:** Based on your analysis, perform parameter fine-tuning to optimize model performance. Adjust the following parameters:\n",
        "   - **Learning Rate:** Experiment with different learning rates (higher and lower values) to find an optimal rate.\n",
        "   - **Milestones:** Modify the milestone values for adjusting the learning rate schedule.\n",
        "   - **Weight Decay:** Explore different weight decay values.\n",
        "   \n",
        "\n",
        "3. **Re-Training:** Train the model with the adjusted hyperparameters. Record the training progress and generate a new report, including performance metrics and line plots as before.\n",
        "\n",
        "4. **Final Analysis:** Analyze the results of the fine-tuned model and compare them with the initial training. Answer the following questions:\n",
        "   - Has parameter fine-tuning improved model performance?\n",
        "   - Did it mitigate overfitting or underfitting issues?\n",
        "   - What can you conclude about the optimal hyperparameters for this task?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi3ybeUnBXrh"
      },
      "source": [
        "## Calculating MPJPE for a Specific Frame  (**2 Points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QscgEyYVBXrh"
      },
      "source": [
        "\n",
        "In this exercise, you will calculate the Mean Per Joint Position Error (MPJPE) for a specific frame. This skill is valuable for assessing the accuracy of your model's predictions at a particular moment.\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{MPJPE}_t = \\frac{1}{N} \\sum_{j=1}^{J} \\left\\| P_{\\text{predicted}_{t,j}} - P_{\\text{gt}_{t,j}} \\right\\|\n",
        "\\end{align*}\n",
        "\n",
        "Fixed the frame $t$, you will calculate the MPJPE for the predicted pose and the ground truth. Steps:\n",
        "\n",
        "- Write a function that takes in input the predicted pose and the ground truth one and returns the MPJPE for a number of frames $t$. (e.g. the output could be a dictionary with the frame number as key and the MPJPE as value)\n",
        "- Rewrite the test function to use the function you just wrote.\n",
        "- Run the newly created test function for $t=[5, 10, 15, 25]$ and report the results in a table and plot.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "mYQK7SB2BXri"
      },
      "outputs": [],
      "source": [
        "from utils.loss_funcs import mpjpe_error\n",
        "\n",
        "def mpjpe_per_frame(sequences_predict,sequences_gt, frames_to_consider):\n",
        "    '''\n",
        "    Insert your code below\n",
        "    '''\n",
        "\n",
        "    #create the dictionary\n",
        "    results = {}\n",
        "\n",
        "    #select only the frames to consider\n",
        "    for frame in frames_to_consider:\n",
        "\n",
        "      #(8,25,96)\n",
        "      #select the predicted frame and the grounf truth frame\n",
        "      pred_frame = sequences_predict[:,frame-1]\n",
        "      gt_frame = sequences_gt[:,frame-1]\n",
        "\n",
        "      sequences_predict[:,frame-1]\n",
        "\n",
        "      #calculate the error with the utils function\n",
        "      error = mpjpe_error(pred_frame, gt_frame).item()\n",
        "\n",
        "      #save in a dictionary\n",
        "      results[frame] = error\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "w0arCQrDBXri"
      },
      "outputs": [],
      "source": [
        "def test_per_frame(ckpt_path=None):\n",
        "    model.load_state_dict(torch.load(ckpt_path))\n",
        "    print('model loaded')\n",
        "    model.eval()\n",
        "    accum_loss=0\n",
        "\n",
        "\n",
        "    ############################\n",
        "    #aggiunto da noi\n",
        "    action_mpjpe_dict = {}\n",
        "    total_loss_per_frame = {5: 0, 10: 0, 15: 0, 25: 0}\n",
        "    total_sequences = 0\n",
        "\n",
        "    ############################\n",
        "\n",
        "    n_batches=0 # number of batches for all the sequences\n",
        "    actions=define_actions(actions_to_consider_test)\n",
        "    dim_used = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25,\n",
        "                      26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
        "                      46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68,\n",
        "                      75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92])\n",
        "\n",
        "    # joints at same loc\n",
        "    joint_to_ignore = np.array([16, 20, 23, 24, 28, 31])\n",
        "    index_to_ignore = np.concatenate((joint_to_ignore * 3, joint_to_ignore * 3 + 1, joint_to_ignore * 3 + 2))\n",
        "    joint_equal = np.array([13, 19, 22, 13, 27, 30])\n",
        "    index_to_equal = np.concatenate((joint_equal * 3, joint_equal * 3 + 1, joint_equal * 3 + 2))\n",
        "    totalll=0\n",
        "    counter=0\n",
        "    for action in actions:\n",
        "      running_loss=0\n",
        "      n=0\n",
        "      dataset_test = datasets.Datasets(path,input_n,output_n,skip_rate, split=2,actions=[action])\n",
        "      #print('>>> test action for sequences: {:d}'.format(dataset_test.__len__()))\n",
        "\n",
        "      test_loader = DataLoader(dataset_test, batch_size=batch_size_test, shuffle=False, num_workers=0, pin_memory=True)\n",
        "      for cnt,batch in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "\n",
        "          batch=batch.to(device)\n",
        "          batch_dim=batch.shape[0]\n",
        "          n+=batch_dim\n",
        "\n",
        "\n",
        "          all_joints_seq=batch.clone()[:, input_n:input_n+output_n,:]\n",
        "\n",
        "          sequences_train=batch[:, 0:input_n, dim_used].view(-1,input_n,len(dim_used)//3,3).permute(0,3,1,2)\n",
        "          sequences_gt=batch[:, input_n:input_n+output_n, :]\n",
        "\n",
        "\n",
        "          running_time = time.time()\n",
        "          sequences_predict=model(sequences_train).view(-1, output_n, joints_to_consider, 3)\n",
        "          #sequences_predict = model(sequences_train)\n",
        "          totalll += time.time()-running_time\n",
        "          counter += 1\n",
        "          sequences_predict=sequences_predict.contiguous().view(-1,output_n,len(dim_used))\n",
        "\n",
        "          all_joints_seq[:,:,dim_used] = sequences_predict\n",
        "\n",
        "\n",
        "          all_joints_seq[:,:,index_to_ignore] = all_joints_seq[:,:,index_to_equal]\n",
        "\n",
        "          '''\n",
        "          Insert your code below.\n",
        "          The function mpjpe_per_frame should return the loss for each frame in the sequence. (e.g. a dictionary with keys the frames and values the loss for each frame)\n",
        "          Keep a tab of the running loss for each frame and the number of frames in the sequence.\n",
        "          '''\n",
        "          frames_to_consider = [5, 10, 15, 25]\n",
        "\n",
        "          #get the mpjpe error\n",
        "          dict_loss = mpjpe_per_frame(all_joints_seq, sequences_gt, frames_to_consider)\n",
        "\n",
        "          #sum the value with respect to the frame\n",
        "          for frame, loss in dict_loss.items():\n",
        "                total_loss_per_frame[frame] += loss\n",
        "\n",
        "          #TODO check counter: questo contatore potrebbe essere inutile\n",
        "          total_sequences += 1\n",
        "\n",
        "      '''\n",
        "      Insert your code below.\n",
        "      Average the loss over all the frames in the sequence and print the results.\n",
        "      '''\n",
        "\n",
        "      #now we need to do the average\n",
        "      avg_loss_per_frame = {frame: loss / total_sequences for frame, loss in total_loss_per_frame.items()}\n",
        "\n",
        "      #print the result for every action\n",
        "      print(str(action),': ', str(avg_loss_per_frame))\n",
        "\n",
        "      #update the dictionary\n",
        "      action_mpjpe_dict[f\"avg_loss_per_frame/{action}\"] = avg_loss_per_frame\n",
        "\n",
        "    #return the dictionary (not asked but it might be usefull later on)\n",
        "    return action_mpjpe_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9sky2L9BXrj",
        "outputId": "7392b95d-e38f-4870-876e-3feb806fe233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded\n",
            "walking :  {5: 44.32815420627594, 10: 64.00082993507385, 15: 68.15737843513489, 25: 84.83458387851715}\n",
            "eating :  {5: 39.98060429096222, 10: 58.07935589551926, 15: 67.38003921508789, 25: 86.27773660421371}\n",
            "smoking :  {5: 39.704097052415214, 10: 57.108338038126625, 15: 66.61454304059346, 25: 84.7838278611501}\n",
            "discussion :  {5: 42.39425779879093, 10: 62.94074243307114, 15: 75.52508652210236, 25: 94.5915487408638}\n",
            "directions :  {5: 42.80865187644959, 10: 64.99470739364624, 15: 78.50930118560791, 25: 98.44614200592041}\n",
            "greeting :  {5: 45.65099300940832, 10: 70.08042653401692, 15: 84.89530710379283, 25: 106.08230217297871}\n",
            "phoning :  {5: 45.28975030354091, 10: 69.40071739469256, 15: 84.68185901641846, 25: 107.0617937701089}\n",
            "posing :  {5: 47.2402161359787, 10: 73.39574255049229, 15: 91.0595914721489, 25: 116.3053272664547}\n",
            "purchases :  {5: 48.8585504160987, 10: 75.45564100477431, 15: 93.63328165478177, 25: 119.16542241308424}\n",
            "sitting :  {5: 49.21282447576523, 10: 75.55675045251846, 15: 94.04832285642624, 25: 119.95459114313125}\n",
            "sittingdown :  {5: 51.222297018224545, 10: 77.51477546041662, 15: 96.60574231364511, 25: 123.21797595240854}\n",
            "takingphoto :  {5: 51.209738194942474, 10: 77.370742837588, 15: 96.72384072343509, 25: 123.79891350865364}\n",
            "waiting :  {5: 50.9602656181042, 10: 77.19217061079465, 15: 96.44687350896689, 25: 123.36554143062004}\n",
            "walkingdog :  {5: 52.71506794861385, 10: 79.23389590638024, 15: 98.41058846030917, 25: 125.75902256795338}\n",
            "walkingtogether :  {5: 51.83750867843628, 10: 77.91046815713247, 15: 96.47457219759623, 25: 122.98799773057301}\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Insert your code below where you want to load the model and test it.\n",
        "You need to specify the path to the model checkpoint file and call the test function.\n",
        "'''\n",
        "ckpt_path = './checkpoints/h36m_3d_25frames_ckpt_epoch_40.pt'\n",
        "dic_error_per_frame = test_per_frame(ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVcNnOJMBXrk"
      },
      "source": [
        "## Iterative Mechanism (**3 Points**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSSW3wgYBXrk"
      },
      "source": [
        "In this exercise, you will explore the concept of an iterative mechanism and its adaptability when the model's output length changes. You will start with a model designed to produce 25 output frames but adapt it to generate only 10. The exercise will involve modifying and re-training the model for the new output length. During test time, the model will generate 10 frames and then use them as input to generate the successive 10 frames, and so on, until the desired number of frames is reached. In this case, you are asked to generate 25 frames.\n",
        "\n",
        "The steps are as follows:\n",
        "- Change the model's output length from 25 to 10.\n",
        "- Re-train the model.\n",
        "- Rewrite the test function to generate 25 frames using the iterative mechanism.\n",
        "- Generate a new report and compare the results to the baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Bas-0-OHBXrk"
      },
      "outputs": [],
      "source": [
        "# # Arguments to setup the datasets\n",
        "datas = 'h36m' # dataset name\n",
        "\n",
        "#this was changed to the path of the dataset\n",
        "path = './data/h3.6m/h3.6m/dataset'\n",
        "input_n=10 # number of frames to train on (default=10)\n",
        "\n",
        "'''\n",
        "Insert your code below\n",
        "'''\n",
        "output_n= 10 # number of frames to predict on\n",
        "\n",
        "input_dim=3 # dimensions of the input coordinates(default=3)\n",
        "skip_rate=1 # # skip rate of frames\n",
        "joints_to_consider=22\n",
        "\n",
        "#FLAGS FOR THE TRAINING\n",
        "mode='train' #choose either train or test mode\n",
        "\n",
        "batch_size_test=8\n",
        "model_path_iterative= './checkpoints_iterative/' # path to the model checkpoint file\n",
        "\n",
        "actions_to_consider_test='all' # actions to test on.\n",
        "model_name = datas+'_3d_'+str(output_n)+'frames_ckpt' #the model name to save/load\n",
        "\n",
        "#FLAGS FOR THE VISUALIZATION\n",
        "actions_to_consider_viz='all' # actions to visualize\n",
        "visualize_from='test'\n",
        "n_viz=2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMoSKaitBXrl",
        "outputId": "ec97fbfb-9a69-495d-eaca-0102078c956f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Train Dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/AML/Practice/utils/h36motion3d.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  subs = np.array([[1, 6, 7, 8, 9], [11], [5]]) # , 6, 7, 8, 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Validation Dataset...\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "print('Loading Train Dataset...')\n",
        "dataset = datasets.Datasets(path,input_n, output_n,skip_rate, split=0)\n",
        "\n",
        "#dataset = datasets.Datasets(path,input_n,output_n,skip_rate, split=0)\n",
        "print('Loading Validation Dataset...')\n",
        "vald_dataset = datasets.Datasets(path,input_n,25,skip_rate, split=1)\n",
        "\n",
        "#! Note: Ignore warning:  \"VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "aRFyVcL9BXrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23be0ff3-ec8e-4b0d-d4d7-e45972d1fa01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Training dataset length: 182327\n",
            ">>> Validation dataset length: 28110\n"
          ]
        }
      ],
      "source": [
        "batch_size=256\n",
        "\n",
        "print('>>> Training dataset length: {:d}'.format(dataset.__len__()))\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)#\n",
        "\n",
        "print('>>> Validation dataset length: {:d}'.format(vald_dataset.__len__()))\n",
        "vald_loader = DataLoader(vald_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7OAb9s6BXrl",
        "outputId": "293788c9-c658-41f9-a824-dc278633bd35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "total number of parameters of the network is: 26694\n"
          ]
        }
      ],
      "source": [
        "from models.sttr.sttformer import Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n",
        "\n",
        "n_heads = 1\n",
        "\n",
        "model = Model(num_joints=joints_to_consider,\n",
        "                 num_frames=input_n, num_frames_out=output_n, num_heads=n_heads,\n",
        "                 num_channels=3, kernel_size=[3,3], use_pes=True).to(device)\n",
        "\n",
        "print('total number of parameters of the network is: '+str(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "aYdpdrcmBXrl"
      },
      "outputs": [],
      "source": [
        "# Arguments to setup the optimizer\n",
        "lr=1e-01 # learning rate\n",
        "use_scheduler=True # use MultiStepLR scheduler\n",
        "milestones=[10,30]   # the epochs after which the learning rate is adjusted by gamma\n",
        "gamma=0.1 #gamma correction to the learning rate, after reaching the milestone epochs\n",
        "weight_decay=1e-05 # weight decay (L2 penalty)\n",
        "optimizer=optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "if use_scheduler:\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "clip_grad=None # select max norm to clip gradients\n",
        "# Argument for training\n",
        "n_epochs=41\n",
        "log_step = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3_T38zzBXrm"
      },
      "source": [
        "### Train and Validation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps_FldQMBXrm"
      },
      "outputs": [],
      "source": [
        "save_and_plot = True # save the model and plot the loss. Change to True if you want to save the model and plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EaiHzL3lBXrm",
        "outputId": "273c2a13-10a8-4bd7-d416-3224f7da3f07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:0mmllljh) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rich-pine-4</strong> at: <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/0mmllljh' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/0mmllljh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231023_170634-0mmllljh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:0mmllljh). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/AML/Practice/wandb/run-20231023_170806-sls9u2b6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/sls9u2b6' target=\"_blank\">electric-armadillo-5</a></strong> to <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/sls9u2b6' target=\"_blank\">https://wandb.ai/rampo/Spatio-Temporal%20Transformer%20fine-tuning/runs/sls9u2b6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch: 1, Iteration:     1]  training loss: 561.468\n",
            "[Epoch: 1, Iteration:   201]  training loss: 100.764\n",
            "[Epoch: 1, Iteration:   401]  training loss: 81.175\n",
            "[Epoch: 1, Iteration:   601]  training loss: 79.338\n",
            "[Epoch: 1, Iteration:     1]  validation loss: 70.752\n",
            "[Epoch: 2, Iteration:     1]  training loss: 71.223\n",
            "[Epoch: 2, Iteration:   201]  training loss: 71.027\n",
            "[Epoch: 2, Iteration:   401]  training loss: 67.543\n",
            "[Epoch: 2, Iteration:   601]  training loss: 67.209\n",
            "[Epoch: 2, Iteration:     1]  validation loss: 69.046\n",
            "[Epoch: 3, Iteration:     1]  training loss: 68.254\n",
            "[Epoch: 3, Iteration:   201]  training loss: 65.446\n",
            "[Epoch: 3, Iteration:   401]  training loss: 64.769\n",
            "[Epoch: 3, Iteration:   601]  training loss: 62.314\n",
            "[Epoch: 3, Iteration:     1]  validation loss: 73.221\n",
            "[Epoch: 4, Iteration:     1]  training loss: 62.883\n",
            "[Epoch: 4, Iteration:   201]  training loss: 60.926\n",
            "[Epoch: 4, Iteration:   401]  training loss: 58.821\n",
            "[Epoch: 4, Iteration:   601]  training loss: 58.597\n",
            "[Epoch: 4, Iteration:     1]  validation loss: 52.677\n",
            "[Epoch: 5, Iteration:     1]  training loss: 60.922\n",
            "[Epoch: 5, Iteration:   201]  training loss: 60.548\n",
            "[Epoch: 5, Iteration:   401]  training loss: 56.829\n",
            "[Epoch: 5, Iteration:   601]  training loss: 58.661\n",
            "[Epoch: 5, Iteration:     1]  validation loss: 68.203\n",
            "[Epoch: 6, Iteration:     1]  training loss: 68.784\n",
            "[Epoch: 6, Iteration:   201]  training loss: 58.111\n",
            "[Epoch: 6, Iteration:   401]  training loss: 57.979\n",
            "[Epoch: 6, Iteration:   601]  training loss: 56.347\n",
            "[Epoch: 6, Iteration:     1]  validation loss: 59.097\n",
            "[Epoch: 7, Iteration:     1]  training loss: 63.949\n",
            "[Epoch: 7, Iteration:   201]  training loss: 52.725\n",
            "[Epoch: 7, Iteration:   401]  training loss: 52.946\n",
            "[Epoch: 7, Iteration:   601]  training loss: 54.476\n",
            "[Epoch: 7, Iteration:     1]  validation loss: 53.739\n",
            "[Epoch: 8, Iteration:     1]  training loss: 52.183\n",
            "[Epoch: 8, Iteration:   201]  training loss: 54.736\n",
            "[Epoch: 8, Iteration:   401]  training loss: 58.919\n",
            "[Epoch: 8, Iteration:   601]  training loss: 52.704\n",
            "[Epoch: 8, Iteration:     1]  validation loss: 62.218\n",
            "[Epoch: 9, Iteration:     1]  training loss: 57.735\n",
            "[Epoch: 9, Iteration:   201]  training loss: 52.886\n",
            "[Epoch: 9, Iteration:   401]  training loss: 55.366\n",
            "[Epoch: 9, Iteration:   601]  training loss: 48.893\n",
            "[Epoch: 9, Iteration:     1]  validation loss: 54.315\n",
            "[Epoch: 10, Iteration:     1]  training loss: 58.475\n",
            "[Epoch: 10, Iteration:   201]  training loss: 53.059\n",
            "[Epoch: 10, Iteration:   401]  training loss: 53.487\n",
            "[Epoch: 10, Iteration:   601]  training loss: 54.326\n",
            "[Epoch: 10, Iteration:     1]  validation loss: 49.716\n",
            "[Epoch: 11, Iteration:     1]  training loss: 53.796\n",
            "[Epoch: 11, Iteration:   201]  training loss: 48.681\n",
            "[Epoch: 11, Iteration:   401]  training loss: 50.263\n",
            "[Epoch: 11, Iteration:   601]  training loss: 52.962\n",
            "[Epoch: 11, Iteration:     1]  validation loss: 45.152\n",
            "[Epoch: 12, Iteration:     1]  training loss: 50.495\n",
            "[Epoch: 12, Iteration:   201]  training loss: 49.888\n",
            "[Epoch: 12, Iteration:   401]  training loss: 53.144\n",
            "[Epoch: 12, Iteration:   601]  training loss: 50.035\n",
            "[Epoch: 12, Iteration:     1]  validation loss: 45.355\n",
            "[Epoch: 13, Iteration:     1]  training loss: 48.373\n",
            "[Epoch: 13, Iteration:   201]  training loss: 48.665\n",
            "[Epoch: 13, Iteration:   401]  training loss: 47.622\n",
            "[Epoch: 13, Iteration:   601]  training loss: 50.040\n",
            "[Epoch: 13, Iteration:     1]  validation loss: 46.542\n",
            "[Epoch: 14, Iteration:     1]  training loss: 53.809\n",
            "[Epoch: 14, Iteration:   201]  training loss: 46.102\n",
            "[Epoch: 14, Iteration:   401]  training loss: 46.579\n",
            "[Epoch: 14, Iteration:   601]  training loss: 49.826\n",
            "[Epoch: 14, Iteration:     1]  validation loss: 45.002\n",
            "[Epoch: 15, Iteration:     1]  training loss: 48.595\n",
            "[Epoch: 15, Iteration:   201]  training loss: 48.633\n",
            "[Epoch: 15, Iteration:   401]  training loss: 51.313\n",
            "[Epoch: 15, Iteration:   601]  training loss: 54.015\n",
            "[Epoch: 15, Iteration:     1]  validation loss: 46.247\n",
            "[Epoch: 16, Iteration:     1]  training loss: 48.543\n",
            "[Epoch: 16, Iteration:   201]  training loss: 48.554\n",
            "[Epoch: 16, Iteration:   401]  training loss: 46.903\n",
            "[Epoch: 16, Iteration:   601]  training loss: 51.327\n",
            "[Epoch: 16, Iteration:     1]  validation loss: 44.927\n",
            "[Epoch: 17, Iteration:     1]  training loss: 48.068\n",
            "[Epoch: 17, Iteration:   201]  training loss: 48.382\n",
            "[Epoch: 17, Iteration:   401]  training loss: 48.259\n",
            "[Epoch: 17, Iteration:   601]  training loss: 50.155\n",
            "[Epoch: 17, Iteration:     1]  validation loss: 48.939\n",
            "[Epoch: 18, Iteration:     1]  training loss: 48.207\n",
            "[Epoch: 18, Iteration:   201]  training loss: 49.258\n",
            "[Epoch: 18, Iteration:   401]  training loss: 49.736\n",
            "[Epoch: 18, Iteration:   601]  training loss: 47.987\n",
            "[Epoch: 18, Iteration:     1]  validation loss: 45.633\n",
            "[Epoch: 19, Iteration:     1]  training loss: 48.859\n",
            "[Epoch: 19, Iteration:   201]  training loss: 46.691\n",
            "[Epoch: 19, Iteration:   401]  training loss: 44.313\n",
            "[Epoch: 19, Iteration:   601]  training loss: 49.112\n",
            "[Epoch: 19, Iteration:     1]  validation loss: 47.972\n",
            "[Epoch: 20, Iteration:     1]  training loss: 49.357\n",
            "[Epoch: 20, Iteration:   201]  training loss: 47.611\n",
            "[Epoch: 20, Iteration:   401]  training loss: 46.696\n",
            "[Epoch: 20, Iteration:   601]  training loss: 53.601\n",
            "[Epoch: 20, Iteration:     1]  validation loss: 43.111\n",
            "[Epoch: 21, Iteration:     1]  training loss: 51.523\n",
            "[Epoch: 21, Iteration:   201]  training loss: 44.977\n",
            "[Epoch: 21, Iteration:   401]  training loss: 45.417\n",
            "[Epoch: 21, Iteration:   601]  training loss: 47.586\n",
            "[Epoch: 21, Iteration:     1]  validation loss: 45.516\n",
            "[Epoch: 22, Iteration:     1]  training loss: 51.392\n",
            "[Epoch: 22, Iteration:   201]  training loss: 47.138\n",
            "[Epoch: 22, Iteration:   401]  training loss: 46.010\n",
            "[Epoch: 22, Iteration:   601]  training loss: 49.597\n",
            "[Epoch: 22, Iteration:     1]  validation loss: 43.348\n",
            "[Epoch: 23, Iteration:     1]  training loss: 47.113\n",
            "[Epoch: 23, Iteration:   201]  training loss: 48.891\n",
            "[Epoch: 23, Iteration:   401]  training loss: 46.795\n",
            "[Epoch: 23, Iteration:   601]  training loss: 48.434\n",
            "[Epoch: 23, Iteration:     1]  validation loss: 46.794\n",
            "[Epoch: 24, Iteration:     1]  training loss: 45.285\n",
            "[Epoch: 24, Iteration:   201]  training loss: 47.925\n",
            "[Epoch: 24, Iteration:   401]  training loss: 47.453\n",
            "[Epoch: 24, Iteration:   601]  training loss: 48.423\n",
            "[Epoch: 24, Iteration:     1]  validation loss: 45.163\n",
            "[Epoch: 25, Iteration:     1]  training loss: 48.274\n",
            "[Epoch: 25, Iteration:   201]  training loss: 48.744\n",
            "[Epoch: 25, Iteration:   401]  training loss: 48.128\n",
            "[Epoch: 25, Iteration:   601]  training loss: 46.246\n",
            "[Epoch: 25, Iteration:     1]  validation loss: 42.866\n",
            "[Epoch: 26, Iteration:     1]  training loss: 46.862\n",
            "[Epoch: 26, Iteration:   201]  training loss: 48.111\n",
            "[Epoch: 26, Iteration:   401]  training loss: 45.291\n",
            "[Epoch: 26, Iteration:   601]  training loss: 47.927\n",
            "[Epoch: 26, Iteration:     1]  validation loss: 43.656\n",
            "[Epoch: 27, Iteration:     1]  training loss: 45.705\n",
            "[Epoch: 27, Iteration:   201]  training loss: 48.845\n",
            "[Epoch: 27, Iteration:   401]  training loss: 44.339\n",
            "[Epoch: 27, Iteration:   601]  training loss: 48.138\n",
            "[Epoch: 27, Iteration:     1]  validation loss: 44.199\n",
            "[Epoch: 28, Iteration:     1]  training loss: 47.309\n",
            "[Epoch: 28, Iteration:   201]  training loss: 47.776\n",
            "[Epoch: 28, Iteration:   401]  training loss: 48.684\n",
            "[Epoch: 28, Iteration:   601]  training loss: 46.393\n",
            "[Epoch: 28, Iteration:     1]  validation loss: 44.205\n",
            "[Epoch: 29, Iteration:     1]  training loss: 43.823\n",
            "[Epoch: 29, Iteration:   201]  training loss: 48.249\n",
            "[Epoch: 29, Iteration:   401]  training loss: 48.195\n",
            "[Epoch: 29, Iteration:   601]  training loss: 46.878\n",
            "[Epoch: 29, Iteration:     1]  validation loss: 48.162\n",
            "[Epoch: 30, Iteration:     1]  training loss: 47.885\n",
            "[Epoch: 30, Iteration:   201]  training loss: 48.611\n",
            "[Epoch: 30, Iteration:   401]  training loss: 46.139\n",
            "[Epoch: 30, Iteration:   601]  training loss: 47.246\n",
            "[Epoch: 30, Iteration:     1]  validation loss: 43.987\n",
            "[Epoch: 31, Iteration:     1]  training loss: 47.583\n",
            "[Epoch: 31, Iteration:   201]  training loss: 46.527\n",
            "[Epoch: 31, Iteration:   401]  training loss: 47.431\n",
            "[Epoch: 31, Iteration:   601]  training loss: 49.477\n",
            "[Epoch: 31, Iteration:     1]  validation loss: 44.320\n",
            "[Epoch: 32, Iteration:     1]  training loss: 48.313\n",
            "[Epoch: 32, Iteration:   201]  training loss: 49.859\n",
            "[Epoch: 32, Iteration:   401]  training loss: 46.198\n",
            "[Epoch: 32, Iteration:   601]  training loss: 46.995\n",
            "[Epoch: 32, Iteration:     1]  validation loss: 43.064\n",
            "[Epoch: 33, Iteration:     1]  training loss: 44.831\n",
            "[Epoch: 33, Iteration:   201]  training loss: 44.861\n",
            "[Epoch: 33, Iteration:   401]  training loss: 50.742\n",
            "[Epoch: 33, Iteration:   601]  training loss: 46.562\n",
            "[Epoch: 33, Iteration:     1]  validation loss: 43.490\n",
            "[Epoch: 34, Iteration:     1]  training loss: 49.312\n",
            "[Epoch: 34, Iteration:   201]  training loss: 47.952\n",
            "[Epoch: 34, Iteration:   401]  training loss: 47.751\n",
            "[Epoch: 34, Iteration:   601]  training loss: 49.751\n",
            "[Epoch: 34, Iteration:     1]  validation loss: 45.999\n",
            "[Epoch: 35, Iteration:     1]  training loss: 46.942\n",
            "[Epoch: 35, Iteration:   201]  training loss: 49.313\n",
            "[Epoch: 35, Iteration:   401]  training loss: 46.208\n",
            "[Epoch: 35, Iteration:   601]  training loss: 46.739\n",
            "[Epoch: 35, Iteration:     1]  validation loss: 44.070\n",
            "[Epoch: 36, Iteration:     1]  training loss: 49.983\n",
            "[Epoch: 36, Iteration:   201]  training loss: 47.101\n",
            "[Epoch: 36, Iteration:   401]  training loss: 49.191\n",
            "[Epoch: 36, Iteration:   601]  training loss: 47.795\n",
            "[Epoch: 36, Iteration:     1]  validation loss: 43.203\n",
            "[Epoch: 37, Iteration:     1]  training loss: 45.888\n",
            "[Epoch: 37, Iteration:   201]  training loss: 44.313\n",
            "[Epoch: 37, Iteration:   401]  training loss: 46.325\n",
            "[Epoch: 37, Iteration:   601]  training loss: 46.798\n",
            "[Epoch: 37, Iteration:     1]  validation loss: 43.109\n",
            "[Epoch: 38, Iteration:     1]  training loss: 45.646\n",
            "[Epoch: 38, Iteration:   201]  training loss: 46.373\n",
            "[Epoch: 38, Iteration:   401]  training loss: 46.608\n",
            "[Epoch: 38, Iteration:   601]  training loss: 44.416\n",
            "[Epoch: 38, Iteration:     1]  validation loss: 43.068\n",
            "[Epoch: 39, Iteration:     1]  training loss: 48.354\n",
            "[Epoch: 39, Iteration:   201]  training loss: 47.668\n",
            "[Epoch: 39, Iteration:   401]  training loss: 45.244\n",
            "[Epoch: 39, Iteration:   601]  training loss: 46.207\n",
            "[Epoch: 39, Iteration:     1]  validation loss: 44.472\n",
            "[Epoch: 40, Iteration:     1]  training loss: 46.741\n",
            "[Epoch: 40, Iteration:   201]  training loss: 50.042\n",
            "[Epoch: 40, Iteration:   401]  training loss: 45.771\n",
            "[Epoch: 40, Iteration:   601]  training loss: 45.463\n",
            "[Epoch: 40, Iteration:     1]  validation loss: 47.321\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# launch training with the new output_n\n",
        "train(data_loader,vald_loader, path_to_save_model=model_path_iterative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flw5562hBXrm"
      },
      "source": [
        "### Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "0yi1JCPdBXrm"
      },
      "outputs": [],
      "source": [
        "def test(ckpt_path=None):\n",
        "    model.load_state_dict(torch.load(ckpt_path))\n",
        "    print('model loaded')\n",
        "    model.eval()\n",
        "    accum_loss=0\n",
        "    n_batches=0 # number of batches for all the sequences\n",
        "    actions=define_actions(actions_to_consider_test)\n",
        "    dim_used = np.array([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25,\n",
        "                      26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
        "                      46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68,\n",
        "                      75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 88, 89, 90, 91, 92])\n",
        "\n",
        "     ############################\n",
        "    #aggiunto da noi\n",
        "    action_mpjpe_dict = {}\n",
        "    total_loss_per_frame = {5: 0, 10: 0, 15: 0, 25: 0}\n",
        "    total_sequences = 0\n",
        "\n",
        "    ############################\n",
        "    # joints at same loc\n",
        "    joint_to_ignore = np.array([16, 20, 23, 24, 28, 31])\n",
        "    index_to_ignore = np.concatenate((joint_to_ignore * 3, joint_to_ignore * 3 + 1, joint_to_ignore * 3 + 2))\n",
        "    joint_equal = np.array([13, 19, 22, 13, 27, 30])\n",
        "    index_to_equal = np.concatenate((joint_equal * 3, joint_equal * 3 + 1, joint_equal * 3 + 2))\n",
        "    totalll=0\n",
        "    counter=0\n",
        "    for action in actions:\n",
        "      running_loss=0\n",
        "      n=0\n",
        "      dataset_test = datasets.Datasets(path,input_n,25,skip_rate, split=2,actions=[action])\n",
        "      #print('>>> test action for sequences: {:d}'.format(dataset_test.__len__()))\n",
        "\n",
        "      test_loader = DataLoader(dataset_test, batch_size=batch_size_test, shuffle=False, num_workers=0, pin_memory=True)\n",
        "      for cnt,batch in enumerate(test_loader):\n",
        "        with torch.no_grad():\n",
        "\n",
        "          batch=batch.to(device)\n",
        "          batch_dim=batch.shape[0]\n",
        "          n+=batch_dim\n",
        "\n",
        "          all_joints_seq=batch.clone()[:, input_n:input_n+25,:]\n",
        "\n",
        "          sequences_train=batch[:, 0:input_n, dim_used].view(-1,input_n,len(dim_used)//3,3).permute(0,3,1,2)\n",
        "          sequences_gt=batch[:, input_n:input_n+25, :]\n",
        "\n",
        "          running_time = time.time()\n",
        "\n",
        "          sequences_predict=model(sequences_train).view(-1, output_n, joints_to_consider, 3)\n",
        "          #sequences_predict = model(sequences_train)\n",
        "          totalll += time.time()-running_time\n",
        "          counter += 1\n",
        "          '''\n",
        "          Insert your code below. You will need to iteratively predict the next frames and feed it to back to the model until you reach the desired number of frames.\n",
        "          '''\n",
        "\n",
        "          # NB: the dimension of the input of the model is (8,3,10,22)\n",
        "          # so we need to permute the newly obtained output, to be inserted in the input\n",
        "          sp_permuted = sequences_predict.permute(0, 3, 1, 2)\n",
        "\n",
        "          # Use this new input sequence (sp_permuted) to predict the next 10 frames.\n",
        "          sequences_next_predict = model(sp_permuted).view(-1, output_n, joints_to_consider, 3)\n",
        "\n",
        "          # concatenate the new output with the old one, we will have 20 predicted frames after this\n",
        "          sequences_final_predict = torch.cat((sequences_predict, sequences_next_predict[:, :, :, :]), dim=1)\n",
        "\n",
        "          # permute the new output to be inserted as the input (same as before)\n",
        "          snp_permuted = sequences_next_predict.permute(0, 3, 1, 2)\n",
        "\n",
        "          # Use this new input sequence to predict the next 10 frames.\n",
        "          sequences_next_predict2 = model(snp_permuted).view(-1, output_n, joints_to_consider, 3)\n",
        "\n",
        "          # concatenate the next 5\n",
        "          sequences_final_predict = torch.cat((sequences_final_predict, sequences_next_predict2[:, :5, :, :]), dim=1)\n",
        "\n",
        "          frames_to_consider = [5, 10, 15, 25]\n",
        "\n",
        "          # Assign sequences_final_predict to the new tensor\n",
        "          # Reshape sequences_final_predict to have a shape of [8, 25, 66]\n",
        "\n",
        "          sequences_final_predict_reshaped = sequences_final_predict.view(batch_dim, 25, -1)\n",
        "          all_joints_seq[:, :, dim_used] = sequences_final_predict_reshaped\n",
        "          all_joints_seq[:,:,index_to_ignore] = all_joints_seq[:,:,index_to_equal]\n",
        "\n",
        "          # get the mpjpe error\n",
        "          dict_loss = mpjpe_per_frame(all_joints_seq, sequences_gt, frames_to_consider)\n",
        "\n",
        "          # sum the value with respect to the frame\n",
        "          for frame, loss in dict_loss.items():\n",
        "                total_loss_per_frame[frame] += loss\n",
        "\n",
        "          #TODO check counter: questo contatore potrebbe essere inutile\n",
        "          total_sequences += 1\n",
        "\n",
        "      '''\n",
        "      Insert your code below.\n",
        "      Average the loss over all the frames in the sequence and print the results.\n",
        "      '''\n",
        "\n",
        "      #now we need to do the average\n",
        "      avg_loss_per_frame = {frame: loss / total_sequences for frame, loss in total_loss_per_frame.items()}\n",
        "\n",
        "      #print the result for every action\n",
        "      print(str(action),': ', str(avg_loss_per_frame))\n",
        "\n",
        "      #update the dictionary\n",
        "      action_mpjpe_dict[f\"avg_loss_per_frame/{action}\"] = avg_loss_per_frame\n",
        "\n",
        "    #return the dictionary (not asked but it might be usefull later on)\n",
        "    #return action_mpjpe_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbwZQr2PBXrn",
        "outputId": "65dedf2c-04c0-48e3-d14c-95e9682d7006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded\n",
            "walking :  {5: 38.101313292980194, 10: 58.47386622428894, 15: 72.78038597106934, 25: 84.92221593856812}\n",
            "eating :  {5: 34.9777949154377, 10: 55.11351054906845, 15: 70.69065070152283, 25: 87.82684290409088}\n",
            "smoking :  {5: 34.715791861216225, 10: 53.77352193991343, 15: 69.3064923286438, 25: 87.09954659144084}\n",
            "discussion :  {5: 37.47930258512497, 10: 60.045474857091904, 15: 77.8801577091217, 25: 96.83207023143768}\n",
            "directions :  {5: 38.00996996164322, 10: 62.17199881076813, 15: 80.10676927566529, 25: 100.3052285194397}\n",
            "greeting :  {5: 41.21880826354027, 10: 67.7775569955508, 15: 86.81670773029327, 25: 107.83277269204457}\n",
            "phoning :  {5: 40.878322422504425, 10: 67.26816843237195, 15: 86.88655209541321, 25: 109.402542250497}\n",
            "posing :  {5: 42.43075869232416, 10: 70.83658592402935, 15: 92.5877933204174, 25: 118.47311127185822}\n",
            "purchases :  {5: 44.084454741742874, 10: 73.16646167967055, 15: 95.20744739638434, 25: 121.49231349097357}\n",
            "sitting :  {5: 44.36218095421791, 10: 73.14361218214034, 15: 95.6191910982132, 25: 122.62775452136994}\n",
            "sittingdown :  {5: 46.07453311031515, 10: 74.98643913052298, 15: 98.23993394591592, 25: 126.3343109217557}\n",
            "takingphoto :  {5: 45.848739594221115, 10: 74.56424893935521, 15: 98.02303770184517, 25: 126.72039707501729}\n",
            "waiting :  {5: 45.58192298045525, 10: 74.33040669331184, 15: 97.65933498969444, 25: 126.23798749997066}\n",
            "walkingdog :  {5: 47.16417015450342, 10: 76.48050636053085, 15: 99.8046892455646, 25: 128.55884979452406}\n",
            "walkingtogether :  {5: 46.34886650641759, 10: 75.06657087802887, 15: 97.70370202064514, 25: 125.37151077588399}\n"
          ]
        }
      ],
      "source": [
        "model_path_iterative = './checkpoints_iterative/h36m_3d_10frames_ckpt_epoch_40.pt' # Change the epoch according to the validation curve\n",
        "test(ckpt_path=model_path_iterative)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceuqVt5HBXrn"
      },
      "source": [
        "## YOUR custom model (**3 Points**)\n",
        " In this exercise, you will implement a Transformer-like network (based on the Theory notebook) for this specific task. You can use the Transformer's Encoder and implement your own Decoder to predict future poses. (e.g. RNN, MLP, CNN, TCN, ...).\n",
        " We won't provide any code for this exercise, but you can use the code provided in the Theory notebook as a starting point.\n",
        " The goal of this exercise is not to beat the previous model but to understand how to implement a Transformer network for this specific task. For this reason, the evaluation will be based on the code you write and the explanation you provide in the report rather than the results.\n",
        "\n",
        "\n",
        "### Performance BONUS (**Up to 2 Points**)\n",
        "- **1 Bonus Point** if the model achieves an A-MPJPE between 80 and 90 millimeters.\n",
        "- **2 Bonus Points** if the model achieves an A-MPJPE between 70 and 80 millimeters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dxldHMmBXro"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Input Shape: [batch_size, input_time, joints, 3]\n",
        "\n",
        "Encoder:\n",
        "Input shape: [batch_size, input_time, joints, 3]\n",
        "Output shape: [batch_size, input_time/output_time, joints, FREE]\n",
        "\n",
        "# Decoder:\n",
        "Input shape: [batch_size, input_time/output_time, joints, FREE]\n",
        "Output shape: [batch_size, output_time, joints, 3]\n",
        "\n",
        "\n",
        "Hint: Transformers often take an input of shape [batch_size, time, joints*channels], use the reshape or view function to match the dimensionality.\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fTbGwJFtBXra",
        "iELEXXORBXrf",
        "Mfh69SDiBXrh",
        "W3_T38zzBXrm"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ccdd086b475483295de6391f9f469dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26dd3a1731e64a9b819005d7cd8e7996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ccdd086b475483295de6391f9f469dc",
            "placeholder": "​",
            "style": "IPY_MODEL_882027c62aee457884ca9ae347777451",
            "value": "0.001 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3e865a34ac0842fa8d2bb5b311ae5511": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d6bca113864643ad01f43633f10d9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7286a39848c548d48d6a94d9b87adf6e",
            "value": 0.07414040114613181
          }
        },
        "48d6bca113864643ad01f43633f10d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7286a39848c548d48d6a94d9b87adf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "882027c62aee457884ca9ae347777451": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1335a70ab64f1e82759084cf3521bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26dd3a1731e64a9b819005d7cd8e7996",
              "IPY_MODEL_3e865a34ac0842fa8d2bb5b311ae5511"
            ],
            "layout": "IPY_MODEL_e6bff14e4b7244a09655883fb34c1703"
          }
        },
        "e6bff14e4b7244a09655883fb34c1703": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}