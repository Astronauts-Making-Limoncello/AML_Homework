Using device: cuda - Type: NVIDIA GeForce RTX 3090
ACTIONS_TO_CONSIDER_TRAIN: ['walking']
Loading Train Dataset...
Loading Validation Dataset...
>>> Training dataset length: 15523
>>> Validation dataset length: 1562
Using device: cuda
total number of parameters of the network is: 10240
joint_to_consider_ids: {2, 3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 21, 22, 25, 26, 27, 29, 30}
joints_to_consider_ids_remapped: {2: 0, 3: 1, 4: 2, 5: 3, 7: 4, 8: 5, 9: 6, 10: 7, 12: 8, 13: 9, 14: 10, 15: 11, 17: 12, 18: 13, 19: 14, 21: 15, 22: 16, 25: 17, 26: 18, 27: 19, 29: 20, 30: 21}
len(joint_to_consider_ids): 22
len(dim_used): 66
len(dim_used)//3: 22
n_joints: 22


 --- batch_id: 0 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     1]  training loss: 574.154


 --- batch_id: 1 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     2]  training loss: 534.798


 --- batch_id: 2 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     3]  training loss: 536.653


 --- batch_id: 3 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     4]  training loss: 538.342


 --- batch_id: 4 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     5]  training loss: 535.409


 --- batch_id: 5 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     6]  training loss: 539.319


 --- batch_id: 6 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     7]  training loss: 534.394
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[Epoch: 1, Iteration:     1]  validation loss: 529.667


 --- batch_id: 0 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     1]  training loss: 536.512


 --- batch_id: 1 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     2]  training loss: 531.963


 --- batch_id: 2 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     3]  training loss: 533.313


 --- batch_id: 3 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     4]  training loss: 512.718


 --- batch_id: 4 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     5]  training loss: 496.597


 --- batch_id: 5 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     6]  training loss: 505.814


 --- batch_id: 6 --- 


[train] sequences_train.shape: torch.Size([256, 10, 22, 3])
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[train] sequences_predict.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     7]  training loss: 565.524
[GAT Encoder] layer 1
[GATLayer] h.shape: torch.Size([256, 10, 22, 3])
[GATLayer] W.shape: torch.Size([3, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 10, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 10, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 10, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 10, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 10, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 10, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 10, 22, 20])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GAT Encoder] layer 2
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GAT Encoder] layer 3
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 128])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 128])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 2, 64])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 2, 22, 64])
[_get_attention_scores] a.shape: torch.Size([2, 128, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 2, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 2, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 2, 22, 64])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 4, 22, 128])
[GAT Encoder] h_prime.shape: torch.Size([256, 15, 22, 128])
[GATAuto] h_latent.shape: torch.Size([256, 15, 22, 128])


 ----------- 


[GATLayer] h.shape: torch.Size([256, 15, 22, 128])
[GATLayer] W.shape: torch.Size([128, 20])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 15, 22, 20])
[GATLayer] h_transformed (view).shape: torch.Size([256, 15, 22, 4, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 15, 4, 22, 5])
[_get_attention_scores] a.shape: torch.Size([4, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 15, 4, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] e.shape: torch.Size([256, 15, 4, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 15, 4, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 15, 22, 20])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 20])
[GATLayer] h.shape: torch.Size([256, 2, 22, 20])
[GATLayer] W.shape: torch.Size([20, 40])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 2, 22, 40])
[GATLayer] h_transformed (view).shape: torch.Size([256, 2, 22, 8, 5])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 2, 8, 22, 5])
[_get_attention_scores] a.shape: torch.Size([8, 10, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 2, 8, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] e.shape: torch.Size([256, 2, 8, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 2, 8, 22, 5])
[GATLayer] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 2, 22, 40])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 40])
[GATLayer] h.shape: torch.Size([256, 4, 22, 40])
[GATLayer] W.shape: torch.Size([40, 3])
[GATLayer] h_transformed.shape (after einsum): torch.Size([256, 4, 22, 3])
[GATLayer] h_transformed (view).shape: torch.Size([256, 4, 22, 1, 3])
[GATLayer] h_transformed (permute).shape: torch.Size([256, 4, 1, 22, 3])
[_get_attention_scores] a.shape: torch.Size([1, 6, 1])
[_get_attention_scores] source_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] target_scores.shape: torch.Size([256, 4, 1, 22, 1])
[_get_attention_scores] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] e.shape: torch.Size([256, 4, 1, 22, 22])
[GATLayer] h_prime.shape: torch.Size([256, 4, 1, 22, 3])
[GATLayer] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 4, 22, 3])
[GAT Decoder] h_prime.shape: torch.Size([256, 25, 22, 3])
[GATAuto] h_tilde.shape: torch.Size([256, 25, 22, 3])
[Epoch: 2, Iteration:     1]  validation loss: 528.125
